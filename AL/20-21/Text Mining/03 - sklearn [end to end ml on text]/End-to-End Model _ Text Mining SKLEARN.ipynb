{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example text for model training (SMS messages)\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine the sparse matrix contents\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read file into pandas using a relative path\n",
    "path = 'data/sms.tsv'\n",
    "sms = pd.read_table(path, header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternative: read file into pandas from a URL\n",
    "# url = 'https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv'\n",
    "# sms = pd.read_table(url, header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the shape\n",
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "sms.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15481865284974095"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "747/4825.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "sms['label_num'] = sms.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...          1\n",
       "6   ham  Even my brother is not like to speak with me. ...          0\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...          0\n",
       "8  spam  WINNER!! As a valued network customer you have...          1\n",
       "9  spam  Had your mobile 11 months or more? U R entitle...          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = sms.message\n",
    "y = sms.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179,)\n",
      "(1393,)\n",
      "(4179,)\n",
      "(1393,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Vectorizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_df = 0.7, min_df = 3, max_features = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3402"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x3402 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 32255 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x3402 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 9899 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Building and evaluating a model\n",
    "\n",
    "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98564249820531225"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1201,    7],\n",
       "       [  13,  172]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.27999560e-03,   5.35906488e-05,   6.86104097e-02, ...,\n",
       "         2.65121223e-08,   1.00000000e+00,   1.37733841e-09])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1116397d0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAFoCAYAAACmBqpWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wN559N6bNmJ0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113c3050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pd.Series(y_pred_prob).plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99039958833005182"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comparing models\n",
    "\n",
    "We will compare multinomial Naive Bayes with [logistic regression](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression):\n",
    "\n",
    "> Logistic regression, despite its name, is a **linear model for classification** rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01674208,  0.00687344,  0.02099536, ...,  0.03953477,\n",
       "        0.99692211,  0.00591812])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x111dd0c90>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAFoCAYAAACmBqpWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRpIkFckQI0mSimSIkSRJRfr/6KIy/Hs0fPoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1112d5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pd.Series(y_pred_prob).plot.hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98205312275664036"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99561482011813141"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Examining a model for further insight\n",
    "\n",
    "We will examine the our **trained Naive Bayes model** to calculate the approximate **\"spamminess\" of each token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3402"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'00', u'00 sub', u'000', u'000 bonus', u'000 cash', u'000 homeowners', u'000 prize', u'000 xmas', u'02', u'0207', u'03', u'03 2nd', u'04', u'06', u'0800', u'0800 1956669', u'0800 542', u'08000839402', u'08000839402 call2optout', u'08000930705', u'08000930705 delivery', u'08000938767', u'08000938767 update', u'08001950382', u'08001950382 call2optout', u'08002986906', u'0808', u'0808 145', u'0845', u'0870', u'0870 national', u'08701417012', u'08701417012 profit', u'08702840625', u'08702840625 comuk', u'08707509020', u'08707509020 just', u'0871', u'08712300220', u'08712300220 quoting', u'08712405020', u'08712460324', u'08712460324 10p', u'08718720201', u'09050090044', u'09050090044 toclaim', u'09061209465', u'09061209465 suprman', u'09061221066', u'09061221066 fromm']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'www ldew', u'www ringtones', u'www sms', u'www tlp', u'www urawinner', u'wylie', u'xchat', u'xchat final', u'xmas', u'xmas prize', u'xuhui', u'xx', u'xxx', u'xxxx', u'xy', u'ya', u'yahoo', u'yan', u'yan jiu', u'yar', u'yar lor', u'yay', u'yeah', u'yeah got', u'yeah ll', u'yeah probably', u'yeah sure', u'year', u'year special', u'years', u'yep', u'yes', u'yes callback', u'yes princess', u'yest', u'yesterday', u'yetunde', u'yijue', u'ym', u'yo', u'yoga', u'yr', u'yr prize', u'yrs', u'yummy', u'yup', u'yup ok', u'yup thk', u'zed', u'zed 08701417012']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   4.,   0.,   0.],\n",
       "       [  5.,   3.,  23., ...,   0.,   6.,   3.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3402)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  4.,  0.,  0.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.,   3.,  23., ...,   0.,   6.,   3.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>valid 12hrs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sae</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize claim</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special</th>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12hrs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>176.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tones</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect</th>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land line</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send stop</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chance</th>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000 cash</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>45.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selected</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg</th>\n",
       "      <td>45.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer</th>\n",
       "      <td>8.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guaranteed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win</th>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send</th>\n",
       "      <td>95.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nokia</th>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urgent</th>\n",
       "      <td>5.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>won</th>\n",
       "      <td>14.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash</th>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>219.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply</th>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile</th>\n",
       "      <td>9.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <td>28.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>49.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur</th>\n",
       "      <td>196.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>13.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>45.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham   spam\n",
       "token                      \n",
       "valid 12hrs      0.0   16.0\n",
       "sae              0.0   16.0\n",
       "prize claim      0.0   16.0\n",
       "special         26.0   16.0\n",
       "national rate    0.0   16.0\n",
       "national         0.0   16.0\n",
       "12hrs            0.0   16.0\n",
       "5000             0.0   16.0\n",
       "know           176.0   16.0\n",
       "land             0.0   17.0\n",
       "tones            0.0   17.0\n",
       "collect          3.0   17.0\n",
       "land line        0.0   17.0\n",
       "send stop        1.0   17.0\n",
       "http             0.0   17.0\n",
       "weekly           0.0   18.0\n",
       "time           155.0   18.0\n",
       "10               8.0   19.0\n",
       "8007             0.0   19.0\n",
       "award            1.0   19.0\n",
       "chance           9.0   19.0\n",
       "1000 cash        0.0   19.0\n",
       "help            31.0   19.0\n",
       "number          45.0   20.0\n",
       "selected         3.0   20.0\n",
       "800              0.0   20.0\n",
       "2000             0.0   20.0\n",
       "10p              0.0   20.0\n",
       "valid            0.0   20.0\n",
       "video            2.0   21.0\n",
       "...              ...    ...\n",
       "50               3.0   38.0\n",
       "msg             45.0   38.0\n",
       "18               0.0   38.0\n",
       "com              9.0   40.0\n",
       "customer         8.0   40.0\n",
       "service          3.0   41.0\n",
       "contact         10.0   42.0\n",
       "guaranteed       0.0   42.0\n",
       "week            55.0   44.0\n",
       "win              8.0   45.0\n",
       "send            95.0   46.0\n",
       "nokia            2.0   46.0\n",
       "tone             0.0   47.0\n",
       "urgent           5.0   47.0\n",
       "150p             0.0   48.0\n",
       "new             50.0   48.0\n",
       "uk               1.0   55.0\n",
       "won             14.0   56.0\n",
       "cash            12.0   56.0\n",
       "just           219.0   62.0\n",
       "www              1.0   72.0\n",
       "prize            0.0   75.0\n",
       "reply           27.0   81.0\n",
       "claim            0.0   88.0\n",
       "mobile           9.0   90.0\n",
       "stop            28.0   97.0\n",
       "text            49.0   99.0\n",
       "ur             196.0  101.0\n",
       "txt             13.0  114.0\n",
       "free            45.0  158.0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sort_values('spam')[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3617.,   562.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can calculate the \"spamminess\" of each token, we need to avoid **dividing by zero** and account for the **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awarded 1500</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09061790121</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize claim</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lab</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ham  spam\n",
       "token                  \n",
       "hg            1.0   9.0\n",
       "awarded 1500  1.0   4.0\n",
       "09061790121   1.0   4.0\n",
       "prize claim   1.0  17.0\n",
       "lab           4.0   1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hg</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.016014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awarded 1500</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.007117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09061790121</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.007117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize claim</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.030249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lab</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ham      spam\n",
       "token                           \n",
       "hg            0.000276  0.016014\n",
       "awarded 1500  0.000276  0.007117\n",
       "09061790121   0.000276  0.007117\n",
       "prize claim   0.000276  0.030249\n",
       "lab           0.001106  0.001779"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hg</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>57.923488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awarded 1500</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>25.743772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09061790121</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>25.743772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize claim</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>109.411032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lab</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>1.608986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ham      spam  spam_ratio\n",
       "token                                       \n",
       "hg            0.000276  0.016014   57.923488\n",
       "awarded 1500  0.000276  0.007117   25.743772\n",
       "09061790121   0.000276  0.007117   25.743772\n",
       "prize claim   0.000276  0.030249  109.411032\n",
       "lab           0.001106  0.001779    1.608986"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.158363</td>\n",
       "      <td>572.798932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.135231</td>\n",
       "      <td>489.131673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150p</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.087189</td>\n",
       "      <td>315.361210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tone</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.085409</td>\n",
       "      <td>308.925267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guaranteed</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.076512</td>\n",
       "      <td>276.745552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam  spam_ratio\n",
       "token                                     \n",
       "claim       0.000276  0.158363  572.798932\n",
       "prize       0.000276  0.135231  489.131673\n",
       "150p        0.000276  0.087189  315.361210\n",
       "tone        0.000276  0.085409  308.925267\n",
       "guaranteed  0.000276  0.076512  276.745552"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.054084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lor</th>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.054084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt gt</th>\n",
       "      <td>0.056953</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.031242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt</th>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.027741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.027387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ham      spam  spam_ratio\n",
       "token                                \n",
       "da     0.032900  0.001779    0.054084\n",
       "lor    0.032900  0.001779    0.054084\n",
       "lt gt  0.056953  0.001779    0.031242\n",
       "lt     0.064142  0.001779    0.027741\n",
       "gt     0.064971  0.001779    0.027387"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sort_values('spam_ratio', ascending=False).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look up the spam_ratio for a given token\n",
    "tokens.loc['dating', 'spam_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Practicing this workflow on another dataset\n",
    "\n",
    "Please open the **`exercise.ipynb`** notebook (or the **`exercise.py`** script)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Tuning the vectorizer (discussion)\n",
    "\n",
    "Thus far, we have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:\n",
    "\n",
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "- **Experiment**, and let the data tell you the best approach!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
